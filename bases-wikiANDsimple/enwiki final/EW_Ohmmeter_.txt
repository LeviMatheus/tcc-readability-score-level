
An ohmmeter is an electrical instrument that measures electrical resistance (the opposition offered by a substance to the flow of electric current) . Micro-ohmmeters (microhmmeter or micro ohmmeter) make low resistance measurements. Megohmmeters (also a trademarked device Megger) measure large values of resistance. The unit of measurement for resistance is ohms (Î©).
Design evolution.
The first ohmmeters were based on a type of meter movement known as a 'ratiometer'. These were similar to the galvanometer type movement encountered in later instruments, but instead of hairsprings to supply a restoring force they used conducting 'ligaments'. These provided no net rotational force to the movement. Also, the movement was wound with two coils. One was connected via a series resistor to the battery supply. The second was connected to the same battery supply via a second resistor and the resistor under test. The indication on the meter was proportional to the ratio of the currents through the two coils. This ratio was determined by the magnitude of the resistor under test. The advantages of this arrangement were twofold. First, the indication of the resistance was completely independent of the battery voltage (as long as it actually produced some voltage) and no zero adjustment was required. Second, although the resistance scale was non linear, the scale remained correct over the full deflection range. By interchanging the two coils a second range was provided. This scale was reversed compared to the first. A feature of this type of instrument was that it would continue to indicate a random resistance value once the test leads were disconnected (the action of which disconnected the battery from the movement). Ohmmeters of this type only ever measured resistance as they could not easily be incorporated into a multimeter design. Insulation testers that relied on a hand cranked generator operated on the same principle. This ensured that the indication was wholly independent of the voltage actually produced.
Subsequent designs of ohmmeter provided a small battery to apply a voltage to a resistance via a galvanometer to measure the current through the resistance (battery, galvanometer and resistance all connected in series). The scale of the galvanometer was marked in ohms, because the fixed voltage from the battery assured that as resistance is increased, the current through the meter (and hence deflection) would decrease. Ohmmeters form circuits by themselves, therefore they cannot be used within an assembled circuit. This design is much simpler and cheaper than the former design, and was simple to integrate into a multimeter design and consequently was by far the most common form of analogue ohmmeter. This type of ohmmeter suffers from two inherent disadvantages. First, the meter needs to be zeroed by shorting the measurement points together and performing an adjustment for zero ohms indication prior to each measurement. This is because as the battery voltage decreases with age, the series resistance in the meter needs to be reduced to maintain the zero indication at full deflection. Second, and consequent on the first, the actual deflection for any given resistor under test changes as the internal resistance is altered. It remains correct at the centre of the scale only, which is why such ohmmeter designs always quote the accuracy "at centre scale only".
A more accurate type of ohmmeter has an electronic circuit that passes a constant current (I) through the resistance, and another circuit that measures the voltage (V) across the resistance. These measurements are then digitized with an analog digital converter (adc) after which a microcontroller or microprocessor make the division of the current and voltage according to Ohm's Law and then decode these to a display to offer the user a reading of the resistance value they're measuring at that instant. Since these type of meters already measure current, voltage and resistance all at once, these type of circuits are often used in digital multimeters.
Precision ohmmeters.
For high-precision measurements of very small resistances, the above types of meter are inadequate. This is partly because the change in deflection itself is small when the resistance measured is too small in proportion to the intrinsic resistance of the ohmmeter (which can be dealt with through current division), but mostly because the meter's reading is the sum of the resistance of the measuring leads, the contact resistances and the resistance being measured. To reduce this effect, a precision ohmmeter has four terminals, called Kelvin contacts. Two terminals carry the current from and to the meter, while the other two allow the meter to measure the voltage across the resistor. In this arrangement, the power source is connected in series with the resistance to be measured through the external pair of terminals, while the second pair connects in parallel with the galvanometer which measures the voltage drop. With this type of meter, any voltage drop due to the resistance of the first pair of leads and their contact resistances is ignored by the meter. This four terminal measurement technique is called Kelvin sensing, after William Thomson, Lord Kelvin, who invented the Kelvin bridge in 1861 to measure very low resistances. The Four-terminal sensing method can also be utilized to conduct accurate measurements of low resistances.

