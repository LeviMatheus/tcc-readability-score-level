A Cache algorithm is an algorithm used to manage a cache. When the cache is full, it decides which item should be deleted from the cache. The word "hit rate" describes how often a request can be served from the cache. The term latency describes for how long a cached item can be obtained. Cache alorithms are a trade-off between hit-rate and latency.
Various algorithms also exist to maintain cache coherency. This applies only to situation where "multiple" independent caches are used for the "same" data (for example multiple database servers updating the single shared data file).
